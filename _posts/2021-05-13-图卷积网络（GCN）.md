# 图卷积网络

## 损失函数

线性回归用MSE，单分类问题用交叉熵

先复习一下熵的定义：
$$
H(X)=-\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(p\left(x_{i}\right)\right)
$$

### KL Divergence（相对熵）

$$
D_{K L}(p \| q)=\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(\frac{p\left(x_{i}\right)}{q\left(x_{i}\right)}\right)
$$

### 交叉熵

由于
$$
\begin{aligned}
D_{K L}(p \| q) &=\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(p\left(x_{i}\right)\right)-\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(q\left(x_{i}\right)\right) \\
&=-H(p(x))+\left[-\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(q\left(x_{i}\right)\right)\right]
\end{aligned}
$$
前半部分是$p$的熵，后半部分是交叉熵：
$$
H(p, q)=-\sum_{i=1}^{n} p\left(x_{i}\right) \log \left(q\left(x_{i}\right)\right)
$$
在机器学习中，我们需要评估label和predicts之间的差距，使用KL散度刚刚好，由于KL散度中的前一部分$−H(y)$不变，故在优化过程中，只需要关注交叉熵就可以了。所以一般在机器学习中直接用用交叉熵做loss，评估模型。

原文链接：https://blog.csdn.net/tsyccnh/article/details/79163834

【未完待更】

总结一下就是我发现了一篇讲图卷积网络的很好的文章

何时能懂你的心——图卷积神经网络（GCN） - 蝈蝈的文章 - 知乎 https://zhuanlan.zhihu.com/p/71200936